pipeline {
    agent any
    
    parameters {
        string(
            name: 'GIT_REPO_URL',
            defaultValue: 'https://github.com/kuk86kuk/DataMart_transaction',
            description: 'URL Git-репозитория с конфигами'
        )
        string(
            name: 'CONFIG_DIR',
            defaultValue: './wf',
            description: 'Путь к директории с YAML-конфигами'
        )
        string(
            name: 'DATAMARTS',
            defaultValue: 'DataMart_transaction1',
            description: 'Название витрины'
        )
    }

    environment {
        HADOOP_NAMENODE = "exec"
        AIRFLOW_DAGS_DIR = "/opt/airflow/dags"
        HDFS_SQL_DIR = "/datamarts/${params.DATAMARTS}"
        REPO_NAME = "${env.JOB_NAME}"
    }

    stages {
        stage('Получение кода') {
            steps {
                checkout([
                    $class: 'GitSCM',
                    branches: [[name: '*/main']],
                    extensions: [],
                    userRemoteConfigs: [[
                        url: "${params.GIT_REPO_URL}",
                        credentialsId: 'github-ssh-key'
                        
                    ]]
                ])
                sh 'ls -R'
            }
        }

        stage('Чтение YAML конфигов') {
            steps {
                script {
                    echo "=== НАЧАЛО ОБРАБОТКИ YAML КОНФИГОВ ==="
                    
                    // 1. Обработка common.yaml
                    echo "Поиск common.yaml в ${params.CONFIG_DIR}"
                    def commonConfig = [:]
                    try {
                        commonConfig = readYaml file: "${params.CONFIG_DIR}/common.yaml"
                        echo "Успешно прочитан common.yaml:"
                        echo "Версия: ${commonConfig.version ?: 'не указана'}"
                        echo "Другие параметры: ${commonConfig.findAll { it.key != 'version' }}"
                    } catch (Exception e) {
                        echo "⚠️ ВНИМАНИЕ: Не удалось прочитать common.yaml"
                        echo "Ошибка: ${e.getMessage()}"
                        echo "Продолжаем работу без common.yaml"
                    }

                    // 2. Поиск других YAML-файлов
                    echo "Поиск других YAML-файлов в ${params.CONFIG_DIR}"
                    def findCmd = "find ${params.CONFIG_DIR} -type f \\( -name '*.yaml' -o -name '*.yml' \\) ! -name 'common.yaml' 2>/dev/null || echo ''"
                    echo "Выполняем команду: ${findCmd}"
                    
                    def otherFiles = sh(script: findCmd, returnStdout: true).trim().split('\n')
                    echo "Найдено файлов: ${otherFiles.size()}"
                    
                    def allConfigs = [:]
                    otherFiles.eachWithIndex { filePath, index ->
                        echo "\n=== Обработка файла ${index + 1}/${otherFiles.size()}: ${filePath} ==="
                        // Чтение файла
                        def config = readYaml file: filePath
                        echo "Файл прочитан успешно"
                        
                        // Объединение с commonConfig
                        def mergedConfig = commonConfig + config
                        def configName = filePath.tokenize('/').last().replace('.yaml', '').replace('.yml', '')
                        allConfigs[configName] = mergedConfig
                        
                        // Детальное логирование для kpi_calc.yaml
                        if (configName == 'kpi_calc') {
                            echo "Детали конфига kpi_calc:"
                            echo "Версия: ${mergedConfig.version ?: 'не указана'}"
                            echo "Метаданные: ${mergedConfig.metadata ?: 'отсутствуют'}"
                            echo "Количество задач: ${mergedConfig.tasks?.size() ?: 0}"
                            
                            if (mergedConfig.tasks) {
                                echo "Список задач:"
                                mergedConfig.tasks.each { task ->
                                    echo "- ${task.name} (тип: ${task.type}, скрипт: ${task.script})"
                                }
                            }
                        }
                            
                        
                    }

                    // Сохранение параметров для DAG
                    env.SCHEDULE_INTERVAL = allConfigs.flow?.dependencies?.find { it.name == "full_load" }?.schedule ?: "@daily"
                    env.START_DATE = "2024-01-01"
                    
                    echo "\n=== ИТОГИ ОБРАБОТКИ КОНФИГОВ ==="
                    echo "Всего успешно обработано конфигов: ${allConfigs.size()}"
                    echo "Список конфигов: ${allConfigs.keySet().join(', ')}"
                }
            }
        }

        stage('Проверка соединения') {
            steps {
                script {
                    echo "Проверка namenode (WebHDFS):"
                    sh 'curl -v "http://namenode:9870/webhdfs/v1/?op=LISTSTATUS&user.name=jenkins"'
                    
                    echo "Проверка доступности datanode:"
                    sh '''
                        # Проверяем доступность порта 9864
                        if curl -f -s -o /dev/null -m 5 "http://datanode:9864"; then
                            echo "✅ Datanode доступен на порту 9864"
                            # Альтернативная проверка состояния datanode
                            echo "Попытка получить информацию о блоках:"
                            curl -v "http://namenode:9870/webhdfs/v1/?op=GETCONTENTSUMMARY&user.name=jenkins"
                        else
                            echo "❌ Datanode недоступен на порту 9864"
                            exit 1
                        fi
                    '''
                    
                    echo "Проверка связи между контейнерами:"
                    sh '''
                        # Проверяем разрешение имени
                        echo "IP адрес datanode: $(getent hosts datanode || echo 'Не удалось разрешить имя')"
                        
                        # Альтернативная проверка доступности порта через curl
                        if curl -f -s -o /dev/null -m 5 "http://datanode:9864"; then
                            echo "✅ Соединение с datanode:9864 успешно"
                        else
                            echo "⚠️ Не удалось установить соединение с datanode:9864"
                            echo "Проверка через curl:"
                            curl -v "http://datanode:9864" || true
                            exit 1
                        fi
                    '''
                }
            }
        }

        stage('Загрузка через WebHDFS') {
            steps {
                script {
                    def WEBHDFS_NAMENODE = "http://namenode:9870/webhdfs/v1"
                    def HDFS_USER = "jenkins"
                    def HDFS_BASE_PATH = "${env.HDFS_SQL_DIR}"

                    // Создание корневой директории
                    echo "Создание корневой директории ${HDFS_BASE_PATH}..."
                    sh """
                        curl -f -s -X PUT \
                        '${WEBHDFS_NAMENODE}${HDFS_BASE_PATH}?op=MKDIRS&user.name=${HDFS_USER}'
                    """

                    // Поиск и загрузка всех SQL-файлов с сохранением структуры каталогов
                    dir('sql') {
                        def files = findFiles(glob: '**/*.sql')  // Рекурсивный поиск всех SQL-файлов
                        
                        if (files.size() == 0) {
                            echo "ℹ️ SQL-файлы не найдены"
                            return
                        }

                        files.each { file ->
                            try {
                                // Полный относительный путь от корня папки sql
                                def relativePath = file.path
                                def hdfsFilePath = "${HDFS_BASE_PATH}/${relativePath}"
                                def hdfsDirPath = hdfsFilePath.substring(0, hdfsFilePath.lastIndexOf('/'))
                                
                                // Создаем поддиректории если нужно
                                if (hdfsDirPath.length() > HDFS_BASE_PATH.length()) {
                                    echo "Создание директории ${hdfsDirPath}"
                                    sh """
                                        curl -f -s -X PUT \
                                        '${WEBHDFS_NAMENODE}${hdfsDirPath}?op=MKDIRS&user.name=${HDFS_USER}'
                                    """
                                }

                                echo "⏫ Загрузка ${file.path} в ${hdfsFilePath}"

                                // Получение redirect URL и загрузка файла
                                sh """
                                    redirect_url=\$(curl -f -s -i -X PUT \
                                    '${WEBHDFS_NAMENODE}${hdfsFilePath}?op=CREATE&user.name=${HDFS_USER}&overwrite=true' \
                                    | grep -i '^Location:' | cut -d' ' -f2 | tr -d '\r\n')
                                    
                                    curl -f -s -X PUT -T "${file.path}" "\$redirect_url"
                                """
                                echo "✅ Успешно загружен: ${file.path}"
                            } catch (Exception e) {
                                echo "⚠️ Ошибка загрузки ${file.path}: ${e.getMessage()}"
                            }
                        }
                    }
                }
            }
        }       
    }
}
